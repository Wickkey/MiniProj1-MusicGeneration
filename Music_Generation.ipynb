{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Music_Generation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1sRodikuL8DzbattfS29J-zwPC5N6HYUS",
      "authorship_tag": "ABX9TyN0usctxuPklajc4eNhXiIe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wickkey/MiniProj1-MusicGeneration/blob/master/Music_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHFxzXzZze2P"
      },
      "source": [
        "import os\n",
        "import json \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dropout, TimeDistributed, Dense, Activation, Embedding\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import *\n",
        "from music21 import *\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRkClLq0zigR"
      },
      "source": [
        "data_directory = \"./drive/My Drive/data/\"\n",
        "data_file = \"Data_Tunes.txt\"\n",
        "charIndex_json = 'char_to_index.json'\n",
        "BATCH_SIZE = 16\n",
        "SEQ_LENGTH = 64\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAORtnFSzvoA"
      },
      "source": [
        "def preprocess(data):\n",
        "  list1=list(data)\n",
        "  list2=['\\n','\\n','\\n']\n",
        "  ignore=['X','T','M','S','K','P']\n",
        "  i=0\n",
        "  #to remove Part1:\n",
        "  while(i<len(list1)):\n",
        "    if(((list1[i] in ignore) and (list1[i+1]==\":\"))or list1[i]=='%' ):\n",
        "      del list2[-1]\n",
        "      while(list1[i]!='\\n'):\n",
        "        i=i+1\n",
        "    list2.append(list1[i])\n",
        "    i=i+1\n",
        "  i=0\n",
        "  #to append 'Z'(start token)\n",
        "  preprocess_data=[]\n",
        "  while(i<len(list2)):\n",
        "    if(list2[i]=='\\n'and list2[i+1]=='\\n' and list2[i+2]=='\\n'):\n",
        "      preprocess_data.append('Z')\n",
        "      i=i+3\n",
        "    else:\n",
        "      preprocess_data.append(list2[i])\n",
        "      i=i+1\n",
        "  return preprocess_data"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvwluY8D8yY7"
      },
      "source": [
        "def read_data(preprocess_data):\n",
        "  char_to_index = {ch: i for (i, ch) in enumerate(sorted(list(set(preprocess_data))))}\n",
        "\n",
        "    \n",
        "  with open(os.path.join(data_directory, charIndex_json), mode = \"w\") as f:\n",
        "        json.dump(char_to_index, f)\n",
        "        \n",
        "  index_to_char = {i: ch for (ch, i) in char_to_index.items()}\n",
        "  num_unique_chars = len(char_to_index)\n",
        "  all_characters_as_indices = np.asarray([char_to_index[c] for c in preprocess_data], dtype = np.int32)\n",
        "  return all_characters_as_indices,num_unique_chars"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJpRo_5b816a"
      },
      "source": [
        "def input_output(all_chars_as_indices,num_unique_chars):\n",
        "    total_length = all_chars_as_indices.shape[0]\n",
        "    num_examples=int(total_length/SEQ_LENGTH)\n",
        "    X=np.zeros((num_examples,SEQ_LENGTH))\n",
        "    Y=np.zeros((num_examples,SEQ_LENGTH,num_unique_chars))\n",
        "    for i in range(num_examples):\n",
        "      for j in range(SEQ_LENGTH):\n",
        "        X[i,j]=all_chars_as_indices[i*SEQ_LENGTH+j]\n",
        "        Y[i,j,all_chars_as_indices[i*SEQ_LENGTH+j+1]]=1\n",
        "    return X,Y"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnBv-A2p85AA"
      },
      "source": [
        "def build_model( seq_length, num_unique_chars):\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Embedding(input_dim = num_unique_chars, output_dim = 512, input_shape = (seq_length,))) \n",
        "    \n",
        "    model.add(LSTM(256, return_sequences = True))\n",
        "    model.add(Dropout(0.2))\n",
        "    \n",
        "    model.add(LSTM(256, return_sequences = True))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(LSTM(256, return_sequences = True))\n",
        "    model.add(Dropout(0.2))\n",
        "    \n",
        "    \n",
        "    model.add(TimeDistributed(Dense(num_unique_chars)))\n",
        "\n",
        "    model.add(Activation(\"softmax\"))\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCDkUDNH9AOu"
      },
      "source": [
        "def make_model(num_unique_chars):\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Embedding(input_dim = num_unique_chars, output_dim = 512, batch_input_shape = (1, 1))) \n",
        "  \n",
        "# stateful: If True, the last state for each sample at index i in a batch will be used \n",
        "# as initial state for the sample of index i in the following batch.\n",
        "    model.add(LSTM(256, return_sequences = True, stateful = True))\n",
        "    model.add(Dropout(0.2))\n",
        "    \n",
        "    model.add(LSTM(256, return_sequences = True, stateful = True))\n",
        "    model.add(Dropout(0.2))\n",
        "    \n",
        "    model.add(LSTM(256,return_sequences=True, stateful = True)) \n",
        "    model.add(Dropout(0.2))\n",
        "    \n",
        "    model.add((Dense(num_unique_chars)))\n",
        "    model.add(Activation(\"softmax\"))\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BDL_irf9By9"
      },
      "source": [
        "def generate_sequence(gen_seq_length):\n",
        "    with open(os.path.join(data_directory, charIndex_json)) as f:\n",
        "        char_to_index = json.load(f)\n",
        "    index_to_char = {i:ch for ch, i in char_to_index.items()}\n",
        "    num_unique_chars = len(index_to_char)\n",
        "    \n",
        "    model = make_model(num_unique_chars)\n",
        "    model.load_weights(\"./drive/My Drive/weights.80.hdf5\")\n",
        "     \n",
        "    sequence_index = [char_to_index['A'],char_to_index['E'],char_to_index['D'],char_to_index['#'],char_to_index['C'],char_to_index['B'],]\n",
        "\n",
        "    for _ in range(gen_seq_length):\n",
        "        batch = np.zeros((1, 1))\n",
        "        batch[0, 0] = sequence_index[-1]\n",
        "        \n",
        "        predicted_probs = model.predict_on_batch(batch).ravel()\n",
        "        sample = np.random.choice(range(num_unique_chars), size = 1, p = predicted_probs)\n",
        "        \n",
        "        \n",
        "        sequence_index.append(sample[0])\n",
        "    \n",
        "        \n",
        "    \n",
        "    seq = ''.join(index_to_char[c] for c in sequence_index)\n",
        "    seq='M:4/8\\n'+str(seq)\n",
        "    return seq"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OE1EFniP9E67"
      },
      "source": [
        "def convert_to_midi(abc):\n",
        "    c = converter.subConverters.ConverterABC()\n",
        "    c.registerOutputExtensions = (\"midi\", )\n",
        "    c.parseData(abc)\n",
        "    s = c.stream\n",
        "    s.write('midi', fp='demos1.mid')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8jLBsys9HeL",
        "outputId": "ff59a628-5853-4924-8547-aaf53a602d3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "file = open(os.path.join(data_directory, data_file), mode = 'r')\n",
        "data = file.read()\n",
        "file.close()\n",
        "preprocess_data=preprocess(data)\n",
        "print(set(preprocess_data))\n",
        "all_characters_as_indices,num_unique_chars=read_data(preprocess_data)\n",
        "X,Y=input_output(all_characters_as_indices,num_unique_chars)\n",
        "print(\"length of preprocess_data-{}\".format(len(preprocess_data)))\n",
        "print(\"vocab_size={}\".format(num_unique_chars))\n",
        "print(\"all_characters={}\".format(all_characters_as_indices))\n",
        "print(\"length of all_characters-{}\".format(len(all_characters_as_indices)))\n",
        "print(\"shape of X={}\".format(X.shape))\n",
        "print(\"shape of Y={}\".format(Y.shape))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Z', 'f', '(', '^', 't', ',', 'b', 'r', '|', ':', 'C', 'z', 'L', 'B', '!', ']', 'D', 'c', '\\n', 'u', 'o', '[', '=', '3', 'a', 's', '4', ')', '8', '\"', 'p', '-', '~', '2', 'l', '+', 'd', '1', 'F', 'i', '6', 'R', '/', 'e', 'E', 'g', '\\\\', 'G', '_', '7', 'm', 'V', '#', \"'\", 'A', 'H', 'n', '9', ' '}\n",
            "length of preprocess_data-116963\n",
            "vocab_size=59\n",
            "all_characters=[33 44 57 ... 15 20 57]\n",
            "length of all_characters-116963\n",
            "shape of X=(1827, 64)\n",
            "shape of Y=(1827, 64, 59)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1DQ9HpI9Kx4",
        "outputId": "de5d88f5-931b-46a2-f9f6-2b2afc4e7c77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model=build_model(SEQ_LENGTH,num_unique_chars)\n",
        "model.summary()\n",
        "model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
        "checkpoint=ModelCheckpoint(filepath='weights.{epoch:02d}.hdf5',monitor='loss',save_best_only=True,save_weights_only=True,period=1)\n",
        "model.fit(X,Y,batch_size=16,epochs=80,callbacks=[checkpoint])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 64, 512)           30208     \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 64, 256)           787456    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 64, 256)           0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 64, 256)           525312    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64, 256)           0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 64, 256)           525312    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 64, 256)           0         \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, 64, 59)            15163     \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 64, 59)            0         \n",
            "=================================================================\n",
            "Total params: 1,883,451\n",
            "Trainable params: 1,883,451\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/80\n",
            "115/115 [==============================] - 7s 61ms/step - loss: 3.0931 - accuracy: 0.1877\n",
            "Epoch 2/80\n",
            "115/115 [==============================] - 7s 58ms/step - loss: 2.1922 - accuracy: 0.3895\n",
            "Epoch 3/80\n",
            "115/115 [==============================] - 7s 58ms/step - loss: 1.8389 - accuracy: 0.4478\n",
            "Epoch 4/80\n",
            "115/115 [==============================] - 7s 58ms/step - loss: 1.6656 - accuracy: 0.4743\n",
            "Epoch 5/80\n",
            "115/115 [==============================] - 7s 58ms/step - loss: 1.5721 - accuracy: 0.4953\n",
            "Epoch 6/80\n",
            "115/115 [==============================] - 7s 58ms/step - loss: 1.5092 - accuracy: 0.5136\n",
            "Epoch 7/80\n",
            "115/115 [==============================] - 7s 58ms/step - loss: 1.4477 - accuracy: 0.5311\n",
            "Epoch 8/80\n",
            "115/115 [==============================] - 7s 58ms/step - loss: 1.4004 - accuracy: 0.5425\n",
            "Epoch 9/80\n",
            "115/115 [==============================] - 7s 58ms/step - loss: 1.3566 - accuracy: 0.5561\n",
            "Epoch 10/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 1.3143 - accuracy: 0.5681\n",
            "Epoch 11/80\n",
            " 98/115 [========================>.....] - ETA: 1s - loss: 1.2750 - accuracy: 0.5803"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFHl3VGo9gaa"
      },
      "source": [
        "music = generate_sequence(192)\n",
        "print(\"\\nMUSIC SEQUENCE GENERATED: \\n{}\".format(music))\n",
        "convert_to_midi(music)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtNXAB_AOmLS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}